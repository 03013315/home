{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Profilers  \n",
    "\n",
    "27.4. The Python Profilers  \n",
    "\n",
    "https://docs.python.org/3/library/profile.html\n",
    "\n",
    "<b>Profilers: profile, cProfile, and pstats</b> – Performance analysis of Python programs.\n",
    "\n",
    "https://hg.python.org/cpython/file/3.5/Lib/profile.py\n",
    "\n",
    "https://hg.python.org/cpython/file/3.5/Lib/pstats.py\n",
    "\n",
    "\n",
    "## 27.4.1. Introduction to the profilers\n",
    "\n",
    "`cProfile` and `profile` provide deterministic profiling of Python programs. \n",
    "\n",
    "A profile is a set of statistics that describes how often and for how long various parts of the program executed. These statistics can be formatted into reports via the `pstats` module.\n",
    "\n",
    "The Python standard library provides two different implementations of the same profiling interface:\n",
    "\n",
    "`cProfile` is recommended for most users; it’s a C extension with reasonable overhead that makes it suitable for profiling long-running programs. Based on `lsprof`, contributed by Brett Rosen and Ted Czotter.\n",
    "\n",
    "\n",
    "`profile`, a pure Python module whose interface is imitated by cProfile, but which adds significant overhead to profiled programs. If you’re trying to extend the profiler in some way, the task might be easier with this module. Originally designed and written by Jim Roskind.\n",
    "   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 27.4.2. Instant User’s Manual\n",
    "\n",
    "This section is provided for users that “don’t want to read the manual.” \n",
    "\n",
    "It provides a very brief overview, and allows a user to rapidly perform profiling on an existing application.\n",
    "\n",
    "The most basic starting point in the profile module is `run()`. It takes <b>a string statement</b> as argument, and creates a report of the time spent executing different lines of code while running the statement.   \n",
    "\n",
    "To profile a function that takes a single argument, you can:\n",
    "\n",
    "run `re.compile()` and print profile results like the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import re\n",
    "cProfile.run('re.compile(\"foo|bar\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line indicates that 197 calls were monitored. Of those calls, 192 were primitive, meaning that the call was not induced via recursion. \n",
    "\n",
    "The next line: Ordered by: standard name, indicates that the text string in the far right column was used to sort the output. \n",
    "\n",
    "The column headings include:\n",
    "\n",
    "<b>ncalls</b>: for the number of calls,tottimefor the total time spent in the given function (and excluding time made in calls to sub-functions)\n",
    "\n",
    "<b>percall</b> is the quotient of tottime divided by ncalls\n",
    "\n",
    "<b>cumtime</b> is the cumulative time spent in this and all subfunctions (from invocation till exit). This figure is accurate even for recursive functions.\n",
    "\n",
    "<b>percall</b> is the quotient of cumtime divided by primitive calls\n",
    "\n",
    "<b>filename:lineno(function)</b> provides the respective data of each function\n",
    "\n",
    "<b>When there are two numbers in the first column (for example 3/1)</b>, it means that the function recursed.The second value is the number of primitive calls and the former is the total number of calls. Note that when the function does not recurse, these two values are the same, and only the single figure is printed\n",
    "\n",
    "#### Instead of printing the output at the end of the profile run, you can <b>save the results to a file</b> by specifying a filename to the `run()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import re\n",
    "cProfile.run('re.compile(\"foo|bar\")', 'restats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `pstats` module’s `Stats` class \n",
    "\n",
    "has a variety of methods for manipulating and printing the data saved into a profile results file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pstats\n",
    "p = pstats.Stats('restats')\n",
    "p.strip_dirs().sort_stats(-1).print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `strip_dirs()` method removed the extraneous path from all the module names. \n",
    "\n",
    "The `sort_stats()` method sorted all the entries according to the standard <b>module/line/name</b> string that is printed.\n",
    "\n",
    "The `print_stats()` method printed out all the statistics.\n",
    "\n",
    "#### You might try the following sort calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p.sort_stats('name')\n",
    "p.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first call will actually sort the list by function name,\n",
    "\n",
    "The second call will print out the statistics. \n",
    "\n",
    "#### The following are some interesting calls to experiment with:\n",
    "\n",
    "1 If you want to understand what <b>algorithms are taking time</b>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p.sort_stats('cumulative').print_stats(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This sorts the profile by <b>cumulative time</b> in a function, and then only prints <b>the ten most significant lines</b>. \n",
    "\n",
    "2 If you were looking to see <b>what functions were looping a lot</b>, and taking a lot of time, you would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p.sort_stats('time').print_stats(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to sort according to time spent within each function, and then print the statistics for the top ten functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 This will <b>sort all the statistics by file name</b>, and then print out statistics for <b>only the class init methods</b> (since they are spelled with __init__ in them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p.sort_stats('files').print_stats('__init__')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 This line sorts statistics with a primary key of time, and a secondary key of cumulative time, and then prints out some of the statistics. To be specific, the list is first culled down to 50% (re: .5) of its original size, then only lines containing init are maintained, and that sub-sub-list is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p.sort_stats('time', 'cumulative').print_stats(.5, 'init')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wondered what functions called the above functions, you could now (p is still sorted according to the last criteria) do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p.print_callers(.5, 'init')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want more functionality, <b>you’re going to have to read the manual</b>, or guess what the following functions do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p.print_callees()\n",
    "p.add('restats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27.4.7. Calibration\n",
    "\n",
    "The profiler of the `profile` module <b>subtracts a constant</b> from each event handling time to compensate for the overhead of calling the time function, and socking away the results. \n",
    "\n",
    "By default, the constant is 0.\n",
    "\n",
    "The following procedure can be used to obtain a better constant for a given platform (see Limitations).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import profile\n",
    "pr = profile.Profile()\n",
    "for i in range(5):\n",
    "    print(pr.calibrate(10000))\n",
    "\n",
    "your_computed_bias=pr.calibrate(10000)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method executes the number of Python calls given by the argument, directly and again under the profiler, measuring the time for both. It then computes the hidden overhead per profiler event, and returns that as a float. \n",
    "\n",
    "The object of this exercise is to get a fairly consistent result. If your computer is very fast, or your timer function has poor resolution, you might have to pass 100000, or even 1000000, to get consistent results.\n",
    "\n",
    "When you have a consistent answer, there are <b>three ways</b> you can use it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import profile\n",
    "\n",
    "# 1. Apply computed bias to all Profile instances created hereafter.\n",
    "profile.Profile.bias = your_computed_bias\n",
    "\n",
    "# 2. Apply computed bias to a specific Profile instance.\n",
    "pr = profile.Profile()\n",
    "pr.bias = your_computed_bias\n",
    "\n",
    "# 3. Specify computed bias in instance constructor.\n",
    "pr = profile.Profile(bias=your_computed_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a choice, you are <b>better off choosing a smaller constant</b>, and then your results will <b>“less often”</b> show up as negative in profile statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: profiling fibonacci\n",
    "\n",
    "\n",
    " \n",
    "This recursive version of a fibonacci sequence calculator is especially useful for demonstrating the profile because we can improve the performance so much. The standard report format shows a summary and then details for each function executed.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import profile\n",
    "\n",
    "def fib(n):\n",
    "    # https://en.wikipedia.org/wiki/Fibonacci_number\n",
    "    # http://en.literateprograms.org/Fibonacci_numbers_(Python)\n",
    "    if n == 0 or n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)\n",
    "\n",
    "def fib_seq(n):\n",
    "    seq = [ ]\n",
    "    if n > 0:\n",
    "        seq.extend(fib_seq(n-1))\n",
    "    seq.append(fib(n))\n",
    "    return seq\n",
    "\n",
    "print('RAW')\n",
    "print('=' * 80)\n",
    "profile.run('print(fib_seq(20)); print')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it takes 57356 separate function calls and 3/4 of a second to run. Since there are only 66 primitive calls, we know that the vast majority of those 57k calls were recursive. \n",
    "\n",
    "The details about where time was spent are broken out by function in the listing showing the number of calls, total time spent in the function, time per call (tottime/ncalls), cumulative time spent in a function, and the ratio of cumulative time to primitive calls.\n",
    "\n",
    "Not surprisingly, most of the time here is spent calling `fib()` repeatedly. \n",
    "\n",
    "\n",
    "<img src=\"./img/recursion_without_cache.png\"/> \n",
    "\n",
    "\n",
    "It’s clear this is a very inefficient algorithm: the amount of function calls increases exponentially for increasing values of n—this is because the function calls values that it has already calculated again and again.\n",
    "\n",
    "We needed to speed up a lot of my recursive algorithms. Decorators really came to the rescue in the form of memoization（https://en.wikipedia.org/wiki/Memoization）.\n",
    "\n",
    "The easy way to optimize this would be to cache the values in a dictionary and check to see if that value of n has been called previously. If it has, return it’s value in the dictionary, if not, proceed to call the function. This is memoization. Let’s look at our memoize class:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class memoize:\n",
    "    \n",
    "    # from http://avinashv.net/2008/04/python-decorators-syntactic-sugar/\n",
    "    def __init__(self, function):\n",
    "        self.function = function\n",
    "        #　a dictionary, ｀self.memoized｀, that acts as our cache\n",
    "        self.memoized = {}\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        try:\n",
    "            return self.memoized[args]\n",
    "        except KeyError:\n",
    "            self.memoized[args] = self.function(*args)\n",
    "            return self.memoized[args]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is now a dictionary, ｀self.memoized｀, that acts as our cache, and a change in the exception handling that looks for ｀KeyError｀, which throws an error if a key doesn’t exist in a dictionary. \n",
    "Again, this class is generalized, and will work for any recursive function that could benefit from memoization.\n",
    "\n",
    "We can add <b>a memoize decorator</b> to reduce the number of recursive calls and have a big impact on the performance of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import profile\n",
    "\n",
    "@memoize\n",
    "def fib(n):\n",
    "    # from http://en.literateprograms.org/Fibonacci_numbers_(Python)\n",
    "    if n == 0 or n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)\n",
    "\n",
    "def fib_seq(n):\n",
    "    seq = [ ]\n",
    "    if n > 0:\n",
    "        seq.extend(fib_seq(n-1))\n",
    "    seq.append(fib(n))\n",
    "    return seq\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('MEMOIZED')\n",
    "    print('=' * 80)\n",
    "    profile.run('print(fib_seq(20)); print')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By remembering the <b>Fibonacci</b> value at each level we can avoid most of the recursion and drop down to 145 calls that only take 0.003 seconds. Also notice that the ncalls count for `fib()` shows that it never recurses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See Also： 18.1 Fibonacci Sequences, Revisited\n",
    "\n",
    "The function `fastFib` has a parameter, `memo`, that it uses to keep track of the numbers it has already evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Page 254, Figure 18.3\n",
    "def fastFib(n, memo = {}):\n",
    "    \"\"\"Assumes n is an int >= 0, memo used only by recursive calls\n",
    "       Returns Fibonacci of n\"\"\"\n",
    "    if n == 0 or n == 1:\n",
    "        return 1\n",
    "    try:\n",
    "        return memo[n]\n",
    "    except KeyError:\n",
    "        result = fastFib(n-1, memo) + fastFib(n-2, memo)\n",
    "        memo[n] = result\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import profile\n",
    "\n",
    "def fib_seq(n):\n",
    "    seq = [ ]\n",
    "    if n > 0:\n",
    "        seq.extend(fib_seq(n-1))\n",
    "    seq.append(fastFib(n))\n",
    "    return seq\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('MEMOIZED')\n",
    "    print('=' * 80)\n",
    "    profile.run('print(fib_seq(20)); print')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pstats: Saving and Working With Statistics\n",
    "\n",
    "The standard report created by the profile functions is not very flexible. \n",
    "\n",
    "If it doesn’t meet your needs, you can produce your own reports by saving the raw profiling data from `run()` and processing it separately with the `Stats` class from `pstats`.\n",
    "\n",
    "For example, to run several iterations of the same test and combine the results, you could do something like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import profile\n",
    "import pstats\n",
    "\n",
    "# from profile_fibonacci_memoized import fib, fib_seq\n",
    "\n",
    "# Create 5 set of stats\n",
    "filenames = []\n",
    "for i in range(5):\n",
    "    filename ='profile_stats_%d.stats' % i\n",
    "    profile.run('print(\"%d \" % i,fib_seq(20))', filename)\n",
    "\n",
    "# Read all 5 stats files into a single object\n",
    "stats = pstats.Stats('profile_stats_0.stats')\n",
    "for i in range(1, 5):\n",
    "    stats.add('profile_stats_%d.stats' % i)\n",
    "\n",
    "# Clean up filenames for the report\n",
    "stats.strip_dirs()\n",
    "\n",
    "# Sort the statistics by the cumulative time spent in the function\n",
    "stats.sort_stats('cumulative')\n",
    "stats.print_stats()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The output report is sorted in descending order of cumulative time spent in the function and the directory names are\n",
    "removed from the printed filenames to conserve horizontal space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24.1.4 Limiting Report Contents\n",
    "\n",
    "Since we are studying the performance of `fib()` and `fib_seq()`, we can also restrict the output report to only\n",
    "include those functions using a regular expression to match the `filename:lineno(function)` values we want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import profile\n",
    "import pstats\n",
    "\n",
    "#from profile_fibonacci_memoized import fib, fib_seq\n",
    "\n",
    "# Read all 5 stats files into a single object\n",
    "stats = pstats.Stats('profile_stats_0.stats')\n",
    "for i in range(1, 5):\n",
    "    stats.add('profile_stats_%d.stats' % i)\n",
    "\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('cumulative')\n",
    "\n",
    "# limit output to lines with \"(fib\" in them\n",
    "stats.print_stats('\\(fib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expression includes a literal left paren (() to match against the function name portion of the location value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24.1.5 Caller / Callee Graphs\n",
    "\n",
    "Stats also includes methods for printing the callers and callees of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cProfile as profile\n",
    "import pstats\n",
    "\n",
    "#from profile_fibonacci_memoized import fib, fib_seq\n",
    "\n",
    "# Read all 5 stats files into a single object\n",
    "stats = pstats.Stats('profile_stats_0.stats')\n",
    "for i in range(1, 5):\n",
    "    stats.add('profile_stats_%d.stats' % i)\n",
    "\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('cumulative')\n",
    "\n",
    "print('INCOMING CALLERS:')\n",
    "stats.print_callers('\\(fib')\n",
    "\n",
    "print('OUTGOING CALLEES:')\n",
    "stats.print_callees('\\(fib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
